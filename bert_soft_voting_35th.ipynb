{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zg3a-6HUERk",
        "outputId": "5f20564a-a02f-4fe6-b7c6-5400e10cdbc7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjuU5srTTk9z",
        "outputId": "f6f75ab9-b881-448d-8b82-952b65a7f103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.72-py2.py3-none-any.whl (8.3 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 69.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.72 pyahocorasick-1.4.4 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "!pip install contractions\n",
        "import contractions\n",
        "import re\n",
        "import string\n",
        "import operator\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/projects/kaggle-disaster/train.csv', index_col = 0)\n",
        "test = pd.read_csv('/content/drive/MyDrive/projects/kaggle-disaster/test.csv', index_col = 0)"
      ],
      "metadata": {
        "id": "Z2h11GmzTrkl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def col_concat(df):\n",
        "    df.keyword.fillna('', inplace=True)\n",
        "    df[\"text\"] = df[\"keyword\"].astype(str) + ' ' + df[\"text\"]\n",
        "    \n",
        "col_concat(train)\n",
        "col_concat(test)\n",
        "\n",
        "train = train.drop_duplicates(subset=['text'], keep=False)"
      ],
      "metadata": {
        "id": "5_gKHAr_TtTA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-for-tf2\n",
        "from bert import bert_tokenization\n",
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZPnsZsIT4Nb",
        "outputId": "572c6285-026c-400d-ff88-372d735ccd39"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bert_layer():\n",
        "\n",
        "    m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
        "    bert_layer = hub.KerasLayer(m_url, trainable=True)\n",
        "\n",
        "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "    tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "    \n",
        "    return bert_layer, tokenizer\n",
        "\n",
        "def bert_encode(texts, tokenzier, max_len=512):\n",
        "\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "        \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len-len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "        \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
        "\n",
        "def build_model(bert_layer, max_len=512):\n",
        "\n",
        "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    net = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
        "    net = tf.keras.layers.Dropout(0.2)(net)\n",
        "    # net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
        "    # net = tf.keras.layers.Dropout(0.2)(net)\n",
        "    out = tf.keras.layers.Dense(1, activation='sigmoid')(net)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "4qpcFTExT44s"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# prepare cross validation\n",
        "kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "qo1QMFhlT23f"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "results = []\n",
        "models = []\n",
        "max_len = 64\n",
        "train_num = 0\n",
        "\n",
        "\n",
        "for train_index, val_index in kf.split(train.text.values, train.target.values):\n",
        "    train_num += 1\n",
        "\n",
        "    train_df = train.iloc[train_index]\n",
        "    val_df = train.iloc[val_index]\n",
        "\n",
        "    bert_layer, tokenizer = get_bert_layer()\n",
        "    x_train = bert_encode(train_df.text.values, tokenizer, max_len=max_len)\n",
        "    x_valid = bert_encode(val_df.text.values, tokenizer, max_len=max_len)\n",
        "    train_labels = train_df.target.values\n",
        "    valid_labels = val_df.target.values\n",
        "\n",
        "    model = build_model(bert_layer, max_len=max_len)\n",
        "\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/kaggle/working/model_ver{train_num}.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "    earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
        "\n",
        "    train_history = model.fit(\n",
        "        x_train, train_labels, \n",
        "        validation_data=(x_valid, valid_labels),\n",
        "        epochs=30,\n",
        "        callbacks=[checkpoint, earlystopping],\n",
        "        batch_size=16,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    results.append(max(train_history.history['val_accuracy']))\n",
        "\n",
        "    model.load_weights(f'/kaggle/working/model_ver{train_num}.h5')\n",
        "    models.append(model)\n",
        "    \n",
        "    del model\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    \n",
        "print(np.mean(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEN7OFOiT6Tz",
        "outputId": "b238c425-7f34-496e-f99c-f982ee739dab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "374/374 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.8050\n",
            "Epoch 1: val_accuracy improved from -inf to 0.82754, saving model to /kaggle/working/model_ver1.h5\n",
            "374/374 [==============================] - 117s 279ms/step - loss: 0.4355 - accuracy: 0.8050 - val_loss: 0.3825 - val_accuracy: 0.8275\n",
            "Epoch 2/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.8718\n",
            "Epoch 2: val_accuracy improved from 0.82754 to 0.82888, saving model to /kaggle/working/model_ver1.h5\n",
            "374/374 [==============================] - 100s 267ms/step - loss: 0.3189 - accuracy: 0.8718 - val_loss: 0.4201 - val_accuracy: 0.8289\n",
            "Epoch 3/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.9052\n",
            "Epoch 3: val_accuracy did not improve from 0.82888\n",
            "374/374 [==============================] - 94s 253ms/step - loss: 0.2429 - accuracy: 0.9052 - val_loss: 0.5437 - val_accuracy: 0.7981\n",
            "Epoch 4/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.9382\n",
            "Epoch 4: val_accuracy did not improve from 0.82888\n",
            "374/374 [==============================] - 94s 252ms/step - loss: 0.1623 - accuracy: 0.9382 - val_loss: 0.5420 - val_accuracy: 0.8128\n",
            "Epoch 4: early stopping\n",
            "Epoch 1/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.7961\n",
            "Epoch 1: val_accuracy improved from -inf to 0.81952, saving model to /kaggle/working/model_ver2.h5\n",
            "374/374 [==============================] - 113s 268ms/step - loss: 0.4490 - accuracy: 0.7961 - val_loss: 0.4207 - val_accuracy: 0.8195\n",
            "Epoch 2/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.8683\n",
            "Epoch 2: val_accuracy improved from 0.81952 to 0.82152, saving model to /kaggle/working/model_ver2.h5\n",
            "374/374 [==============================] - 101s 269ms/step - loss: 0.3287 - accuracy: 0.8683 - val_loss: 0.4202 - val_accuracy: 0.8215\n",
            "Epoch 3/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.2504 - accuracy: 0.9036\n",
            "Epoch 3: val_accuracy improved from 0.82152 to 0.82286, saving model to /kaggle/working/model_ver2.h5\n",
            "374/374 [==============================] - 103s 275ms/step - loss: 0.2504 - accuracy: 0.9036 - val_loss: 0.4635 - val_accuracy: 0.8229\n",
            "Epoch 4/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.9276\n",
            "Epoch 4: val_accuracy did not improve from 0.82286\n",
            "374/374 [==============================] - 95s 253ms/step - loss: 0.1843 - accuracy: 0.9276 - val_loss: 0.5220 - val_accuracy: 0.8108\n",
            "Epoch 5/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9569\n",
            "Epoch 5: val_accuracy did not improve from 0.82286\n",
            "374/374 [==============================] - 94s 252ms/step - loss: 0.1094 - accuracy: 0.9569 - val_loss: 0.6520 - val_accuracy: 0.8155\n",
            "Epoch 5: early stopping\n",
            "Epoch 1/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.8061\n",
            "Epoch 1: val_accuracy improved from -inf to 0.85896, saving model to /kaggle/working/model_ver3.h5\n",
            "374/374 [==============================] - 112s 268ms/step - loss: 0.4426 - accuracy: 0.8061 - val_loss: 0.3611 - val_accuracy: 0.8590\n",
            "Epoch 2/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.8670\n",
            "Epoch 2: val_accuracy improved from 0.85896 to 0.86297, saving model to /kaggle/working/model_ver3.h5\n",
            "374/374 [==============================] - 100s 268ms/step - loss: 0.3339 - accuracy: 0.8670 - val_loss: 0.3874 - val_accuracy: 0.8630\n",
            "Epoch 3/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.9001\n",
            "Epoch 3: val_accuracy did not improve from 0.86297\n",
            "374/374 [==============================] - 95s 253ms/step - loss: 0.2583 - accuracy: 0.9001 - val_loss: 0.4131 - val_accuracy: 0.8456\n",
            "Epoch 4/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.1746 - accuracy: 0.9313\n",
            "Epoch 4: val_accuracy did not improve from 0.86297\n",
            "374/374 [==============================] - 98s 261ms/step - loss: 0.1746 - accuracy: 0.9313 - val_loss: 0.4950 - val_accuracy: 0.8396\n",
            "Epoch 4: early stopping\n",
            "Epoch 1/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.8122\n",
            "Epoch 1: val_accuracy improved from -inf to 0.84960, saving model to /kaggle/working/model_ver4.h5\n",
            "374/374 [==============================] - 113s 269ms/step - loss: 0.4371 - accuracy: 0.8122 - val_loss: 0.3788 - val_accuracy: 0.8496\n",
            "Epoch 2/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.8590\n",
            "Epoch 2: val_accuracy did not improve from 0.84960\n",
            "374/374 [==============================] - 95s 253ms/step - loss: 0.3352 - accuracy: 0.8590 - val_loss: 0.3943 - val_accuracy: 0.8356\n",
            "Epoch 3/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.2599 - accuracy: 0.8971\n",
            "Epoch 3: val_accuracy did not improve from 0.84960\n",
            "374/374 [==============================] - 98s 262ms/step - loss: 0.2599 - accuracy: 0.8971 - val_loss: 0.4294 - val_accuracy: 0.8336\n",
            "Epoch 3: early stopping\n",
            "Epoch 1/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.8077\n",
            "Epoch 1: val_accuracy improved from -inf to 0.84425, saving model to /kaggle/working/model_ver5.h5\n",
            "374/374 [==============================] - 113s 268ms/step - loss: 0.4390 - accuracy: 0.8077 - val_loss: 0.3739 - val_accuracy: 0.8443\n",
            "Epoch 2/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8645\n",
            "Epoch 2: val_accuracy did not improve from 0.84425\n",
            "374/374 [==============================] - 95s 253ms/step - loss: 0.3297 - accuracy: 0.8645 - val_loss: 0.4118 - val_accuracy: 0.8389\n",
            "Epoch 3/30\n",
            "374/374 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.9019\n",
            "Epoch 3: val_accuracy did not improve from 0.84425\n",
            "374/374 [==============================] - 95s 253ms/step - loss: 0.2552 - accuracy: 0.9019 - val_loss: 0.4112 - val_accuracy: 0.8443\n",
            "Epoch 3: early stopping\n",
            "0.8417112350463867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- contractions - 0.8429144382476806 평균 나왔으나 제출 점수 0.83787\n",
        "- 마지막 레이어만 학습 - 0.8417112350463867 평균으나 제출 점수 동일 0.84094"
      ],
      "metadata": {
        "id": "t6SuepVqhXxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDI0-Y02gNpT",
        "outputId": "26afc271-a578-4406-d361-a141ba349a4e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8288770318031311,\n",
              " 0.8228609561920166,\n",
              " 0.8629679083824158,\n",
              " 0.8495989441871643,\n",
              " 0.8442513346672058]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soft_voting = pd.DataFrame()\n",
        "x_test = bert_encode(test.text.values, tokenizer, max_len=max_len)\n",
        "\n",
        "for n, m in enumerate(models):\n",
        "    pred_prob = m.predict(x_test)\n",
        "    soft_voting[n] = pred_prob.flatten()"
      ],
      "metadata": {
        "id": "MeHAd0xIT_qQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_voting[5] = (soft_voting[0] + soft_voting[1] + soft_voting[2] + soft_voting[3] + soft_voting[4])/5"
      ],
      "metadata": {
        "id": "H969n8zjUBRp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv('/content/drive/MyDrive/projects/kaggle-disaster/sample_submission.csv')\n",
        "sub['target'] = soft_voting[5].values.round().astype('int32')\n",
        "sub.to_csv('/content/drive/MyDrive/projects/kaggle-disaster/soft_voted_last_layer.csv', index=False)"
      ],
      "metadata": {
        "id": "Rrdz0vswUB6h"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}